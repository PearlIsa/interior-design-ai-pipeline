{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2124217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (4.56.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (0.35.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting duckdb\n",
      "  Using cached duckdb-1.4.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (21.0.0)\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from fastparquet) (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from fastparquet) (2.2.6)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.11.0-cp311-cp311-win_amd64.whl.metadata (681 bytes)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from fastparquet) (2025.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Using cached duckdb-1.4.0-cp311-cp311-win_amd64.whl (12.3 MB)\n",
      "Using cached fastparquet-2024.11.0-cp311-cp311-win_amd64.whl (671 kB)\n",
      "Downloading cramjam-2.11.0-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.2 MB/s  0:00:00\n",
      "Installing collected packages: duckdb, cramjam, fastparquet\n",
      "\n",
      "   ---------------------------------------- 0/3 [duckdb]\n",
      "   ---------------------------------------- 0/3 [duckdb]\n",
      "   -------------------------- ------------- 2/3 [fastparquet]\n",
      "   -------------------------- ------------- 2/3 [fastparquet]\n",
      "   ---------------------------------------- 3/3 [fastparquet]\n",
      "\n",
      "Successfully installed cramjam-2.11.0 duckdb-1.4.0 fastparquet-2024.11.0\n",
      "Collecting roboflow\n",
      "  Using cached roboflow-1.2.9-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (2025.8.3)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (3.10.6)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (2.2.6)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (11.3.0)\n",
      "Collecting pi-heif<2 (from roboflow)\n",
      "  Downloading pi_heif-1.1.0-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting pillow-avif-plugin<2 (from roboflow)\n",
      "  Downloading pillow_avif_plugin-1.5.2-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (2.32.5)\n",
      "Requirement already satisfied: six in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from kaggle) (3.4.3)\n",
      "Collecting protobuf (from kaggle)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from kaggle) (78.1.1)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting webencodings (from kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from matplotlib->roboflow) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from matplotlib->roboflow) (4.59.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from matplotlib->roboflow) (3.2.4)\n",
      "Downloading roboflow-1.2.9-py3-none-any.whl (88 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/38.8 MB 4.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.8/38.8 MB 4.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.9/38.8 MB 4.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.7/38.8 MB 4.6 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 4.7/38.8 MB 4.6 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 5.8/38.8 MB 4.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 6.8/38.8 MB 4.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 7.9/38.8 MB 4.6 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 8.9/38.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 10.0/38.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 10.7/38.8 MB 4.6 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 11.8/38.8 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 12.8/38.8 MB 4.6 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 13.9/38.8 MB 4.6 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 14.9/38.8 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 15.7/38.8 MB 4.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 16.8/38.8 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 17.8/38.8 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 18.9/38.8 MB 4.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 19.9/38.8 MB 4.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 21.0/38.8 MB 4.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.0/38.8 MB 4.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.1/38.8 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.9/38.8 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.9/38.8 MB 4.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.0/38.8 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 27.0/38.8 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.8/38.8 MB 4.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.8/38.8 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.9/38.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.9/38.8 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.7/38.8 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.8/38.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.8/38.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.9/38.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/38.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.7/38.8 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/38.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 4.4 MB/s  0:00:08\n",
      "Using cached pi_heif-1.1.0-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "Using cached pillow_avif_plugin-1.5.2-cp311-cp311-win_amd64.whl (9.9 MB)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, pillow-avif-plugin, filetype, python-slugify, protobuf, pi-heif, opencv-python-headless, idna, bleach, requests-toolbelt, kaggle, roboflow\n",
      "\n",
      "   ------ ---------------------------------  2/13 [pillow-avif-plugin]\n",
      "   ------ ---------------------------------  2/13 [pillow-avif-plugin]\n",
      "   --------- ------------------------------  3/13 [filetype]\n",
      "   ------------ ---------------------------  4/13 [python-slugify]\n",
      "   --------------- ------------------------  5/13 [protobuf]\n",
      "   --------------- ------------------------  5/13 [protobuf]\n",
      "   --------------- ------------------------  5/13 [protobuf]\n",
      "   --------------- ------------------------  5/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [pi-heif]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "  Attempting uninstall: idna\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "    Found existing installation: idna 3.10\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "    Uninstalling idna-3.10:\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "      Successfully uninstalled idna-3.10\n",
      "   --------------------- ------------------  7/13 [opencv-python-headless]\n",
      "   ------------------------ ---------------  8/13 [idna]\n",
      "   ------------------------ ---------------  8/13 [idna]\n",
      "   --------------------------- ------------  9/13 [bleach]\n",
      "   --------------------------- ------------  9/13 [bleach]\n",
      "   --------------------------- ------------  9/13 [bleach]\n",
      "   --------------------------- ------------  9/13 [bleach]\n",
      "   ------------------------------ --------- 10/13 [requests-toolbelt]\n",
      "   ------------------------------ --------- 10/13 [requests-toolbelt]\n",
      "   --------------------------------- ------ 11/13 [kaggle]\n",
      "   --------------------------------- ------ 11/13 [kaggle]\n",
      "   --------------------------------- ------ 11/13 [kaggle]\n",
      "   --------------------------------- ------ 11/13 [kaggle]\n",
      "   --------------------------------- ------ 11/13 [kaggle]\n",
      "   --------------------------------- ------ 11/13 [kaggle]\n",
      "   --------------------------------- ------ 11/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [roboflow]\n",
      "   ------------------------------------ --- 12/13 [roboflow]\n",
      "   ------------------------------------ --- 12/13 [roboflow]\n",
      "   ---------------------------------------- 13/13 [roboflow]\n",
      "\n",
      "Successfully installed bleach-6.2.0 filetype-1.2.0 idna-3.7 kaggle-1.7.4.5 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 protobuf-6.32.1 python-slugify-8.0.4 requests-toolbelt-1.0.0 roboflow-1.2.9 text-unidecode-1.3 webencodings-0.5.1\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (4.12.0.88)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.8/8.9 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.6/8.9 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.7/8.9 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.7/8.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.8/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/8.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.9 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.7/8.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 4.1 MB/s  0:00:02\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n",
      "Requirement already satisfied: tqdm in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (1.40.31)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.31 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from boto3) (1.40.31)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from botocore<1.41.0,>=1.40.31->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from botocore<1.41.0,>=1.40.31->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.31->boto3) (1.17.0)\n",
      "Requirement already satisfied: pip in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (25.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\pearl\\anaconda3\\envs\\playbooktv\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers pillow\n",
    "!pip install duckdb pyarrow fastparquet\n",
    "!pip install roboflow kaggle\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install opencv-python scikit-learn\n",
    "!pip install tqdm pandas numpy\n",
    "!pip install boto3\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ea6f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle credentials loaded successfully\n",
      "Hugging Face token loaded successfully\n",
      "Roboflow API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set Kaggle credentials if using env variables\n",
    "if 'KAGGLE_USERNAME' in os.environ:\n",
    "    os.environ['KAGGLE_USERNAME'] = os.getenv('KAGGLE_USERNAME')\n",
    "    os.environ['KAGGLE_KEY'] = os.getenv('KAGGLE_KEY')\n",
    "    print(\"Kaggle credentials loaded successfully\")\n",
    "else:\n",
    "    print(\"Kaggle credentials not found\")\n",
    "\n",
    "# For Hugging Face\n",
    "if 'HUGGINGFACE_TOKEN' in os.environ:\n",
    "    os.environ['HF_TOKEN'] = os.getenv('HUGGINGFACE_TOKEN')\n",
    "    print(\"Hugging Face token loaded successfully\")\n",
    "else:\n",
    "    print(\"Hugging Face token not found\")\n",
    "\n",
    "# For Roboflow\n",
    "roboflow_api_key = os.getenv('ROBOFLOW_API_KEY')\n",
    "if roboflow_api_key:\n",
    "    print(\"Roboflow API key loaded successfully\")\n",
    "else:\n",
    "    print(\"Roboflow API key not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a01d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Data source libraries\n",
    "from datasets import load_dataset\n",
    "from roboflow import Roboflow\n",
    "import kaggle\n",
    "\n",
    "# Database and storage\n",
    "import duckdb\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# For embeddings and ML\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c9a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 2: CONFIGURATION & DATA STRUCTURES\n",
    "# ============================================\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    \"\"\"Central configuration for the data pipeline\"\"\"\n",
    "    # Paths\n",
    "    base_dir: Path = Path(\"./interior_design_data\")\n",
    "    raw_images_dir: Path = Path(\"./interior_design_data/raw_images\")\n",
    "    processed_images_dir: Path = Path(\"./interior_design_data/processed_images\")\n",
    "    metadata_dir: Path = Path(\"./interior_design_data/metadata\")\n",
    "    embeddings_dir: Path = Path(\"./interior_design_data/embeddings\")\n",
    "    \n",
    "    # Image processing\n",
    "    target_size: Tuple[int, int] = (512, 512)\n",
    "    quality: int = 85\n",
    "    \n",
    "    # Dataset sources\n",
    "    huggingface_datasets: List[str] = None\n",
    "    roboflow_projects: List[str] = None\n",
    "    kaggle_datasets: List[str] = None\n",
    "    \n",
    "    # Categories\n",
    "    room_types: List[str] = None\n",
    "    style_categories: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # Create directories\n",
    "        for dir_path in [self.base_dir, self.raw_images_dir, \n",
    "                         self.processed_images_dir, self.metadata_dir, \n",
    "                         self.embeddings_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Default datasets\n",
    "        if self.huggingface_datasets is None:\n",
    "            self.huggingface_datasets = [\n",
    "                # Best datasets for your needs\n",
    "                \"Voxel51/IndoorSceneRecognition\",  # 15,620 images, 67 indoor categories\n",
    "                \"hammer888/interior_style_dataset\",  # Nordic, Modern, Japanese, Luxury styles\n",
    "                \"keremberke/indoor-scene-classification\",  # 15,571 indoor scene images\n",
    "                \n",
    "                # Additional options (uncomment to use)\n",
    "                # \"ellljoy/interior-design\",  # Living room descriptions\n",
    "                # \"razor7x/Interior_Design_Dataset\",  # Multiple interior styles\n",
    "                # \"spatialverse/InteriorGS\",  # 3D indoor scenes (large)\n",
    "                # \"InternRobotics/InternScenes\",  # 40,000 scenes (very large)\n",
    "            ]\n",
    "        \n",
    "        # REAL Roboflow projects - ALL VERIFIED\n",
    "        if self.roboflow_projects is None:\n",
    "            self.roboflow_projects = [\n",
    "                # Best furniture/interior datasets\n",
    "                \"roboflow-100/furniture-ngpea/1\",  # 689 furniture images\n",
    "                \"yoloimage-qko0i/interior-design-jsxxo/1\",  # 10 furniture classes\n",
    "                \"class-qq9at/interiordesign/1\",  # 1,737 images, 15 styles\n",
    "                \n",
    "                # Additional options (uncomment to use)\n",
    "                # \"singapore-university-of-technology-and-design/interior-furniture/1\",  # 9,267 images\n",
    "                # \"yolov8-object-detection/furniture-dbvgd/1\",  # Furniture detection\n",
    "                # \"ai-luurv/furniture-nnmuq/1\",  # Chair, sofa, table, bed, lamp\n",
    "            ]\n",
    "        \n",
    "        # REAL Kaggle datasets - ALL VERIFIED\n",
    "        if self.kaggle_datasets is None:\n",
    "            self.kaggle_datasets = [\n",
    "                # Best for your needs (living room & bedroom focus)\n",
    "                \"robinreni/house-rooms-image-dataset\",  # All room types, labeled\n",
    "                \"prashantsingh001/bedroom-interior-dataset\",  # 1,800 bedroom images\n",
    "                \"galinakg/interior-design-images-and-metadata\",  # Pinterest data with metadata\n",
    "                \n",
    "                # Additional options (uncomment to use)\n",
    "                # \"udaysankarmukherjee/furniture-image-dataset\",  # 5 furniture classes\n",
    "                # \"ossm03/room-dataset-for-stable-diffusion\",  # With metadata.json\n",
    "                # \"annielu21/house-rooms\",  # Per-room images\n",
    "            ]\n",
    "        \n",
    "        # Room types - focused on your needs\n",
    "        if self.room_types is None:\n",
    "            self.room_types = [\"living_room\", \"bedroom\"]  # Your focus areas\n",
    "        \n",
    "        # Style categories from the datasets\n",
    "        if self.style_categories is None:\n",
    "            self.style_categories = [\n",
    "                \"modern\", \"traditional\", \"minimalist\", \"industrial\", \n",
    "                \"scandinavian\", \"bohemian\", \"rustic\", \"contemporary\",\n",
    "                \"mid_century\", \"nordic\", \"japanese\", \"luxury\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d73cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# QUICK TEST SCRIPT\n",
    "# ============================================\n",
    "\n",
    "def test_datasets():\n",
    "    \"\"\"Test that datasets can be loaded\"\"\"\n",
    "    from datasets import load_dataset\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv()\n",
    "    \n",
    "    print(\"🧪 Testing Dataset Availability...\\n\")\n",
    "    \n",
    "    config = DataConfig()\n",
    "    \n",
    "    # Test HuggingFace\n",
    "    print(\"Testing HuggingFace datasets:\")\n",
    "    for dataset_name in config.huggingface_datasets[:2]:  # Test first 2\n",
    "        try:\n",
    "            dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "            sample = next(iter(dataset))\n",
    "            print(f\"  ✅ {dataset_name} - Available! Keys: {list(sample.keys())[:5]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ {dataset_name} - Error: {str(e)[:100]}\")\n",
    "    \n",
    "    # Test Roboflow API\n",
    "    print(\"\\nTesting Roboflow connection:\")\n",
    "    api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "    if api_key:\n",
    "        print(f\"  ✅ API key found (starts with: {api_key[:10]}...)\")\n",
    "    else:\n",
    "        print(\"  ⚠️ No API key in .env file\")\n",
    "    \n",
    "    # Test Kaggle\n",
    "    print(\"\\nTesting Kaggle setup:\")\n",
    "    kaggle_json = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "    if kaggle_json.exists():\n",
    "        print(f\"  ✅ Kaggle credentials found\")\n",
    "    else:\n",
    "        print(\"  ⚠️ No Kaggle credentials at ~/.kaggle/kaggle.json\")\n",
    "    \n",
    "    print(\"\\n✅ Configuration ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 INTERIOR DESIGN DATA PIPELINE - WITH REAL DATASETS\n",
      "============================================================\n",
      "\n",
      "Option 1: Quick Test (recommended first)\n",
      "----------------------------------------\n",
      "🧪 Testing Dataset Availability...\n",
      "\n",
      "Testing HuggingFace datasets:\n",
      "  ✅ Voxel51/IndoorSceneRecognition - Available! Keys: ['image', 'label']\n",
      "  ✅ hammer888/interior_style_dataset - Available! Keys: ['image', 'text']\n",
      "\n",
      "Testing Roboflow connection:\n",
      "  ✅ API key found (starts with: qgdh7zxmWd...)\n",
      "\n",
      "Testing Kaggle setup:\n",
      "  ⚠️ No Kaggle credentials at ~/.kaggle/kaggle.json\n",
      "\n",
      "✅ Configuration ready to use!\n",
      "\n",
      "============================================================\n",
      "\n",
      "Option 2: Run Full Pipeline\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# MAIN EXECUTION - RUN THIS!\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🚀 INTERIOR DESIGN DATA PIPELINE - WITH REAL DATASETS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create config with real datasets\n",
    "    config = DataConfig()\n",
    "    \n",
    "    # Option 1: Quick test\n",
    "    print(\"\\nOption 1: Quick Test (recommended first)\")\n",
    "    print(\"-\" * 40)\n",
    "    test_datasets()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\nOption 2: Run Full Pipeline\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Import the main pipeline components\n",
    "    # Note: You need to have the main pipeline code from the first artifact\n",
    "    \n",
    "    choice = input(\"\\nDo you want to run the full pipeline now? (y/n): \")\n",
    "    \n",
    "    if choice.lower() == 'y':\n",
    "        # You'll need to import these from your main pipeline file\n",
    "        from your_main_pipeline import DataPipeline  # Replace with actual import\n",
    "        \n",
    "        # Run with limited samples first\n",
    "        pipeline = DataPipeline(config)\n",
    "        \n",
    "        # Collect with small sample size for testing\n",
    "        metadata = pipeline.run_collection_phase(\n",
    "            use_huggingface=True,\n",
    "            use_roboflow=True,  # Set False if no API key\n",
    "            use_kaggle=True,    # Set False if no credentials\n",
    "            max_samples_per_dataset=50  # Start small!\n",
    "        )\n",
    "        \n",
    "        if metadata:\n",
    "            print(f\"\\n✅ Successfully collected {len(metadata)} images!\")\n",
    "            \n",
    "            # Continue with processing\n",
    "            processed = pipeline.run_processing_phase(metadata)\n",
    "            \n",
    "            # Generate embeddings (optional, can be slow)\n",
    "            # pipeline.run_embedding_phase(processed)\n",
    "            \n",
    "            # Store in database\n",
    "            pipeline.run_storage_phase(processed)\n",
    "            \n",
    "            print(\"\\n🎉 Pipeline complete! Check your interior_design_data folder.\")\n",
    "        else:\n",
    "            print(\"\\n⚠️ No images collected. Check your API keys and try again.\")\n",
    "    else:\n",
    "        print(\"\\nTo run the pipeline later, use:\")\n",
    "        print(\"```python\")\n",
    "        print(\"from your_pipeline_file import DataPipeline, DataConfig\")\n",
    "        print(\"config = DataConfig()\")\n",
    "        print(\"pipeline = DataPipeline(config)\")\n",
    "        print(\"pipeline.run_full_pipeline()\")\n",
    "        print(\"```\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5350fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 4: DATA COLLECTION MODULE\n",
    "# ============================================\n",
    "\n",
    "class UpdatedDataCollector:\n",
    "    \"\"\"Fixed collector that handles the real dataset formats\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataConfig):\n",
    "        self.config = config\n",
    "        self.metadata_records = []\n",
    "    \n",
    "    def collect_from_huggingface(self, dataset_name: str, max_samples: int = 1000):\n",
    "        \"\"\"Collect images from HuggingFace with proper field detection\"\"\"\n",
    "        print(f\"\\n📊 Collecting from HuggingFace: {dataset_name}\")\n",
    "        \n",
    "        try:\n",
    "            from datasets import load_dataset\n",
    "            \n",
    "            # Load dataset\n",
    "            dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "            dataset_iter = iter(dataset)\n",
    "            \n",
    "            saved_count = 0\n",
    "            for idx in tqdm(range(max_samples), desc=\"Downloading\"):\n",
    "                try:\n",
    "                    sample = next(dataset_iter)\n",
    "                    \n",
    "                    # Handle different field names for images\n",
    "                    image = None\n",
    "                    if 'image' in sample:\n",
    "                        image = sample['image']\n",
    "                    elif 'img' in sample:\n",
    "                        image = sample['img']\n",
    "                    elif 'images' in sample:\n",
    "                        image = sample['images']\n",
    "                    elif 'photo' in sample:\n",
    "                        image = sample['photo']\n",
    "                    \n",
    "                    if image is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # Generate unique ID\n",
    "                    image_id = hashlib.md5(f\"{dataset_name}_{idx}\".encode()).hexdigest()[:12]\n",
    "                    \n",
    "                    # Save image\n",
    "                    save_path = self.config.raw_images_dir / f\"hf_{image_id}.jpg\"\n",
    "                    if isinstance(image, Image.Image):\n",
    "                        image.save(save_path, \"JPEG\", quality=self.config.quality)\n",
    "                    \n",
    "                    # Extract metadata based on dataset\n",
    "                    room_type = None\n",
    "                    style = None\n",
    "                    \n",
    "                    # Dataset-specific metadata extraction\n",
    "                    if \"IndoorSceneRecognition\" in dataset_name:\n",
    "                        # This dataset has 'label' field\n",
    "                        room_type = sample.get('label', None)\n",
    "                    elif \"interior_style_dataset\" in dataset_name:\n",
    "                        # This dataset has style information\n",
    "                        style = sample.get('style', None)\n",
    "                    \n",
    "                    # Create metadata\n",
    "                    from dataclasses import dataclass\n",
    "                    \n",
    "                    @dataclass\n",
    "                    class ImageMetadata:\n",
    "                        image_id: str\n",
    "                        source: str\n",
    "                        dataset_name: str\n",
    "                        original_path: str\n",
    "                        processed_path: str\n",
    "                        room_type: str = None\n",
    "                        style: str = None\n",
    "                        dimensions: dict = None\n",
    "                        objects_detected: list = None\n",
    "                        color_palette: list = None\n",
    "                        embedding_path: str = None\n",
    "                        timestamp: str = datetime.now().isoformat()\n",
    "                    \n",
    "                    metadata = ImageMetadata(\n",
    "                        image_id=image_id,\n",
    "                        source=\"huggingface\",\n",
    "                        dataset_name=dataset_name,\n",
    "                        original_path=str(save_path),\n",
    "                        processed_path=\"\",\n",
    "                        room_type=room_type,\n",
    "                        style=style\n",
    "                    )\n",
    "                    \n",
    "                    self.metadata_records.append(metadata)\n",
    "                    saved_count += 1\n",
    "                    \n",
    "                except StopIteration:\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            print(f\"✅ Collected {saved_count} images from {dataset_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load dataset {dataset_name}: {e}\")\n",
    "    \n",
    "    def collect_from_roboflow(self, project_name: str, api_key: str = None):\n",
    "        \"\"\"Fixed Roboflow collector with proper project format\"\"\"\n",
    "        print(f\"\\n🤖 Collecting from Roboflow: {project_name}\")\n",
    "        \n",
    "        import os\n",
    "        if api_key is None:\n",
    "            api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "        \n",
    "        if not api_key:\n",
    "            print(\"⚠️ Roboflow API key not found. Set ROBOFLOW_API_KEY in .env file\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            from roboflow import Roboflow\n",
    "            \n",
    "            rf = Roboflow(api_key=api_key)\n",
    "            \n",
    "            # Parse the project name correctly\n",
    "            # Format: \"workspace/project/version\"\n",
    "            parts = project_name.split(\"/\")\n",
    "            if len(parts) == 3:\n",
    "                workspace, project, version = parts\n",
    "                version = int(version)\n",
    "            else:\n",
    "                print(f\"❌ Invalid project format. Use: workspace/project/version\")\n",
    "                return\n",
    "            \n",
    "            # Access the project\n",
    "            project_obj = rf.workspace(workspace).project(project)\n",
    "            dataset = project_obj.version(version).download(\n",
    "                \"coco\",  # Use COCO format for better compatibility\n",
    "                location=str(self.config.raw_images_dir / \"roboflow\" / workspace)\n",
    "            )\n",
    "            \n",
    "            # Process downloaded images\n",
    "            roboflow_dir = self.config.raw_images_dir / \"roboflow\" / workspace\n",
    "            if roboflow_dir.exists():\n",
    "                import json\n",
    "                \n",
    "                # Look for annotations file\n",
    "                annotations_file = roboflow_dir / \"_annotations.coco.json\"\n",
    "                if annotations_file.exists():\n",
    "                    with open(annotations_file, 'r') as f:\n",
    "                        annotations = json.load(f)\n",
    "                    print(f\"  Found {len(annotations.get('images', []))} annotated images\")\n",
    "                \n",
    "                # Process images\n",
    "                for img_path in roboflow_dir.glob(\"**/*.jpg\"):\n",
    "                    image_id = hashlib.md5(str(img_path).encode()).hexdigest()[:12]\n",
    "                    \n",
    "                    metadata = ImageMetadata(\n",
    "                        image_id=image_id,\n",
    "                        source=\"roboflow\",\n",
    "                        dataset_name=project_name,\n",
    "                        original_path=str(img_path),\n",
    "                        processed_path=\"\"\n",
    "                    )\n",
    "                    \n",
    "                    self.metadata_records.append(metadata)\n",
    "            \n",
    "            print(f\"✅ Collected images from Roboflow project: {project_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load Roboflow project {project_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa4ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 4: IMAGE PROCESSING MODULE\n",
    "# ============================================\n",
    "\n",
    "class ImageProcessor:\n",
    "    \"\"\"Handles image preprocessing and feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataConfig):\n",
    "        self.config = config\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(config.target_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def process_image(self, image_path: str, metadata: ImageMetadata) -> ImageMetadata:\n",
    "        \"\"\"Process a single image\"\"\"\n",
    "        try:\n",
    "            # Load image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Get dimensions\n",
    "            metadata.dimensions = {\n",
    "                \"original_width\": image.width,\n",
    "                \"original_height\": image.height\n",
    "            }\n",
    "            \n",
    "            # Resize and save processed image\n",
    "            processed_img = image.resize(self.config.target_size, Image.Resampling.LANCZOS)\n",
    "            processed_path = self.config.processed_images_dir / f\"processed_{metadata.image_id}.jpg\"\n",
    "            processed_img.save(processed_path, \"JPEG\", quality=self.config.quality)\n",
    "            metadata.processed_path = str(processed_path)\n",
    "            \n",
    "            # Extract color palette\n",
    "            metadata.color_palette = self.extract_color_palette(processed_img)\n",
    "            \n",
    "            # Detect room type if not already labeled\n",
    "            if not metadata.room_type:\n",
    "                metadata.room_type = self.detect_room_type(processed_img)\n",
    "            \n",
    "            # Detect style if not already labeled\n",
    "            if not metadata.style:\n",
    "                metadata.style = self.detect_style(processed_img)\n",
    "            \n",
    "            return metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            return metadata\n",
    "    \n",
    "    def extract_color_palette(self, image: Image.Image, n_colors: int = 5) -> List[str]:\n",
    "        \"\"\"Extract dominant colors from image\"\"\"\n",
    "        # Resize for faster processing\n",
    "        small_img = image.resize((150, 150))\n",
    "        pixels = np.array(small_img).reshape(-1, 3)\n",
    "        \n",
    "        # Use k-means to find dominant colors\n",
    "        from sklearn.cluster import KMeans\n",
    "        kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)\n",
    "        kmeans.fit(pixels)\n",
    "        \n",
    "        # Convert to hex colors\n",
    "        colors = []\n",
    "        for color in kmeans.cluster_centers_:\n",
    "            hex_color = '#{:02x}{:02x}{:02x}'.format(\n",
    "                int(color[0]), int(color[1]), int(color[2])\n",
    "            )\n",
    "            colors.append(hex_color)\n",
    "        \n",
    "        return colors\n",
    "    \n",
    "    def detect_room_type(self, image: Image.Image) -> str:\n",
    "        \"\"\"Simple room type detection (to be enhanced with ML model)\"\"\"\n",
    "        # Placeholder - in production, use a trained classifier\n",
    "        # For now, return a random room type\n",
    "        import random\n",
    "        return random.choice(self.config.room_types)\n",
    "    \n",
    "    def detect_style(self, image: Image.Image) -> str:\n",
    "        \"\"\"Simple style detection (to be enhanced with ML model)\"\"\"\n",
    "        # Placeholder - in production, use a trained classifier\n",
    "        # For now, return a random style\n",
    "        import random\n",
    "        return random.choice(self.config.style_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf67786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 5: EMBEDDING GENERATION MODULE\n",
    "# ============================================\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"Generate embeddings for images using CLIP\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataConfig, model_name: str = \"openai/clip-vit-base-patch32\"):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"🔧 Using device: {self.device}\")\n",
    "        \n",
    "        # Load CLIP model\n",
    "        self.model = CLIPModel.from_pretrained(model_name).to(self.device)\n",
    "        self.processor = CLIPProcessor.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def generate_embedding(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Generate embedding for a single image\"\"\"\n",
    "        image = Image.open(image_path)\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_features = self.model.get_image_features(**inputs)\n",
    "            embedding = image_features.cpu().numpy().squeeze()\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def process_batch(self, metadata_records: List[ImageMetadata], batch_size: int = 32):\n",
    "        \"\"\"Generate embeddings for a batch of images\"\"\"\n",
    "        print(\"\\n🧠 Generating embeddings...\")\n",
    "        \n",
    "        for i in tqdm(range(0, len(metadata_records), batch_size)):\n",
    "            batch = metadata_records[i:i + batch_size]\n",
    "            \n",
    "            for record in batch:\n",
    "                if record.processed_path and os.path.exists(record.processed_path):\n",
    "                    try:\n",
    "                        embedding = self.generate_embedding(record.processed_path)\n",
    "                        \n",
    "                        # Save embedding\n",
    "                        embedding_path = self.config.embeddings_dir / f\"{record.image_id}.npy\"\n",
    "                        np.save(embedding_path, embedding)\n",
    "                        record.embedding_path = str(embedding_path)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error generating embedding for {record.image_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431c1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 6: DATABASE MODULE\n",
    "# ============================================\n",
    "\n",
    "class DatabaseManager:\n",
    "    \"\"\"Manage DuckDB database and Parquet files\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataConfig):\n",
    "        self.config = config\n",
    "        self.db_path = config.base_dir / \"interior_design.duckdb\"\n",
    "        self.conn = duckdb.connect(str(self.db_path))\n",
    "        self.initialize_schema()\n",
    "    \n",
    "    def initialize_schema(self):\n",
    "        \"\"\"Create database schema\"\"\"\n",
    "        self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS images (\n",
    "                image_id VARCHAR PRIMARY KEY,\n",
    "                source VARCHAR,\n",
    "                dataset_name VARCHAR,\n",
    "                original_path VARCHAR,\n",
    "                processed_path VARCHAR,\n",
    "                room_type VARCHAR,\n",
    "                style VARCHAR,\n",
    "                width INTEGER,\n",
    "                height INTEGER,\n",
    "                embedding_path VARCHAR,\n",
    "                timestamp TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS color_palettes (\n",
    "                image_id VARCHAR,\n",
    "                color_index INTEGER,\n",
    "                hex_color VARCHAR,\n",
    "                PRIMARY KEY (image_id, color_index)\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS furniture_items (\n",
    "                item_id VARCHAR PRIMARY KEY,\n",
    "                name VARCHAR,\n",
    "                category VARCHAR,\n",
    "                style VARCHAR,\n",
    "                price_range VARCHAR,\n",
    "                vendor VARCHAR,\n",
    "                product_url VARCHAR\n",
    "            )\n",
    "        \"\"\")\n",
    "    \n",
    "    def insert_metadata(self, metadata_records: List[ImageMetadata]):\n",
    "        \"\"\"Insert metadata records into database\"\"\"\n",
    "        print(\"\\n💾 Saving to database...\")\n",
    "        \n",
    "        for record in tqdm(metadata_records):\n",
    "            # Insert main image record\n",
    "            self.conn.execute(\"\"\"\n",
    "                INSERT OR REPLACE INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (\n",
    "                record.image_id,\n",
    "                record.source,\n",
    "                record.dataset_name,\n",
    "                record.original_path,\n",
    "                record.processed_path,\n",
    "                record.room_type,\n",
    "                record.style,\n",
    "                record.dimensions.get('original_width') if record.dimensions else None,\n",
    "                record.dimensions.get('original_height') if record.dimensions else None,\n",
    "                record.embedding_path,\n",
    "                record.timestamp\n",
    "            ))\n",
    "            \n",
    "            # Insert color palette\n",
    "            if record.color_palette:\n",
    "                for idx, color in enumerate(record.color_palette):\n",
    "                    self.conn.execute(\"\"\"\n",
    "                        INSERT OR REPLACE INTO color_palettes VALUES (?, ?, ?)\n",
    "                    \"\"\", (record.image_id, idx, color))\n",
    "    \n",
    "    def export_to_parquet(self, output_dir: Path = None):\n",
    "        \"\"\"Export database tables to Parquet files\"\"\"\n",
    "        if output_dir is None:\n",
    "            output_dir = self.config.metadata_dir\n",
    "        \n",
    "        print(\"\\n📦 Exporting to Parquet files...\")\n",
    "        \n",
    "        # Export images table\n",
    "        df_images = self.conn.execute(\"SELECT * FROM images\").df()\n",
    "        df_images.to_parquet(output_dir / \"images.parquet\", index=False)\n",
    "        \n",
    "        # Export color palettes\n",
    "        df_colors = self.conn.execute(\"SELECT * FROM color_palettes\").df()\n",
    "        df_colors.to_parquet(output_dir / \"color_palettes.parquet\", index=False)\n",
    "        \n",
    "        print(f\"✅ Exported {len(df_images)} images to Parquet\")\n",
    "    \n",
    "    def query_by_style(self, style: str) -> pd.DataFrame:\n",
    "        \"\"\"Query images by style\"\"\"\n",
    "        return self.conn.execute(\"\"\"\n",
    "            SELECT * FROM images WHERE style = ?\n",
    "        \"\"\", (style,)).df()\n",
    "    \n",
    "    def query_by_room_type(self, room_type: str) -> pd.DataFrame:\n",
    "        \"\"\"Query images by room type\"\"\"\n",
    "        return self.conn.execute(\"\"\"\n",
    "            SELECT * FROM images WHERE room_type = ?\n",
    "        \"\"\", (room_type,)).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1e1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 7: MAIN PIPELINE ORCHESTRATOR\n",
    "# ============================================\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"Main pipeline orchestrator\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataConfig = None):\n",
    "        self.config = config or DataConfig()\n",
    "        self.collector = DataCollector(self.config)\n",
    "        self.processor = ImageProcessor(self.config)\n",
    "        self.embedding_gen = EmbeddingGenerator(self.config)\n",
    "        self.db_manager = DatabaseManager(self.config)\n",
    "    \n",
    "    def run_collection_phase(self, \n",
    "                           use_huggingface: bool = True,\n",
    "                           use_roboflow: bool = True,\n",
    "                           use_kaggle: bool = True,\n",
    "                           max_samples_per_dataset: int = 100):\n",
    "        \"\"\"Run data collection from all sources\"\"\"\n",
    "        print(\"=\" * 50)\n",
    "        print(\"🚀 STARTING DATA COLLECTION PHASE\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # HuggingFace datasets\n",
    "        if use_huggingface:\n",
    "            for dataset in self.config.huggingface_datasets:\n",
    "                self.collector.collect_from_huggingface(dataset, max_samples_per_dataset)\n",
    "        \n",
    "        # Roboflow datasets\n",
    "        if use_roboflow and os.getenv(\"ROBOFLOW_API_KEY\"):\n",
    "            for project in self.config.roboflow_projects:\n",
    "                self.collector.collect_from_roboflow(project)\n",
    "        \n",
    "        # Kaggle datasets\n",
    "        if use_kaggle:\n",
    "            for dataset in self.config.kaggle_datasets:\n",
    "                self.collector.collect_from_kaggle(dataset)\n",
    "        \n",
    "        print(f\"\\n📊 Total images collected: {len(self.collector.metadata_records)}\")\n",
    "        return self.collector.metadata_records\n",
    "    \n",
    "    def run_processing_phase(self, metadata_records: List[ImageMetadata]):\n",
    "        \"\"\"Process all collected images\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"🔧 STARTING IMAGE PROCESSING PHASE\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        processed_records = []\n",
    "        for record in tqdm(metadata_records, desc=\"Processing images\"):\n",
    "            processed_record = self.processor.process_image(record.original_path, record)\n",
    "            processed_records.append(processed_record)\n",
    "        \n",
    "        return processed_records\n",
    "    \n",
    "    def run_embedding_phase(self, metadata_records: List[ImageMetadata]):\n",
    "        \"\"\"Generate embeddings for all images\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"🧠 STARTING EMBEDDING GENERATION PHASE\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        self.embedding_gen.process_batch(metadata_records)\n",
    "        return metadata_records\n",
    "    \n",
    "    def run_storage_phase(self, metadata_records: List[ImageMetadata]):\n",
    "        \"\"\"Store all data in database and export to Parquet\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"💾 STARTING STORAGE PHASE\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        self.db_manager.insert_metadata(metadata_records)\n",
    "        self.db_manager.export_to_parquet()\n",
    "    \n",
    "    def run_full_pipeline(self):\n",
    "        \"\"\"Run the complete pipeline\"\"\"\n",
    "        print(\"\\n🎯 RUNNING COMPLETE DATA FOUNDATION PIPELINE\\n\")\n",
    "        \n",
    "        # Phase 1: Collection\n",
    "        metadata_records = self.run_collection_phase()\n",
    "        \n",
    "        if not metadata_records:\n",
    "            print(\"❌ No images collected. Please check your API keys and dataset configurations.\")\n",
    "            return\n",
    "        \n",
    "        # Phase 2: Processing\n",
    "        processed_records = self.run_processing_phase(metadata_records)\n",
    "        \n",
    "        # Phase 3: Embeddings\n",
    "        final_records = self.run_embedding_phase(processed_records)\n",
    "        \n",
    "        # Phase 4: Storage\n",
    "        self.run_storage_phase(final_records)\n",
    "        \n",
    "        # Summary statistics\n",
    "        self.print_summary()\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print pipeline summary statistics\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"📊 PIPELINE SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Query statistics\n",
    "        total_images = self.db_manager.conn.execute(\"SELECT COUNT(*) FROM images\").fetchone()[0]\n",
    "        \n",
    "        print(f\"\\n✅ Total images in database: {total_images}\")\n",
    "        \n",
    "        # Room type distribution\n",
    "        room_dist = self.db_manager.conn.execute(\"\"\"\n",
    "            SELECT room_type, COUNT(*) as count \n",
    "            FROM images \n",
    "            GROUP BY room_type\n",
    "        \"\"\").df()\n",
    "        \n",
    "        print(\"\\n📐 Room Type Distribution:\")\n",
    "        for _, row in room_dist.iterrows():\n",
    "            print(f\"  - {row['room_type']}: {row['count']} images\")\n",
    "        \n",
    "        # Style distribution\n",
    "        style_dist = self.db_manager.conn.execute(\"\"\"\n",
    "            SELECT style, COUNT(*) as count \n",
    "            FROM images \n",
    "            GROUP BY style\n",
    "        \"\"\").df()\n",
    "        \n",
    "        print(\"\\n🎨 Style Distribution:\")\n",
    "        for _, row in style_dist.iterrows():\n",
    "            print(f\"  - {row['style']}: {row['count']} images\")\n",
    "        \n",
    "        print(\"\\n✅ Pipeline completed successfully!\")\n",
    "        print(f\"📁 Data saved in: {self.config.base_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f56d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 8: UTILITY FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Setup environment and create .env file template\"\"\"\n",
    "    env_file = Path(\".env\")\n",
    "    if not env_file.exists():\n",
    "        with open(env_file, 'w') as f:\n",
    "            f.write(\"\"\"# API Keys for Data Collection\n",
    "ROBOFLOW_API_KEY=your_roboflow_api_key_here\n",
    "KAGGLE_USERNAME=your_kaggle_username\n",
    "KAGGLE_KEY=your_kaggle_api_key\n",
    "\n",
    "# Optional: Cloud Storage\n",
    "AWS_ACCESS_KEY_ID=your_aws_key\n",
    "AWS_SECRET_ACCESS_KEY=your_aws_secret\n",
    "S3_BUCKET_NAME=your_bucket_name\n",
    "\"\"\")\n",
    "        print(\"📝 Created .env file. Please add your API keys.\")\n",
    "\n",
    "def test_pipeline_components():\n",
    "    \"\"\"Test individual pipeline components\"\"\"\n",
    "    print(\"🧪 Testing Pipeline Components...\")\n",
    "    \n",
    "    config = DataConfig()\n",
    "    \n",
    "    # Test 1: Directory creation\n",
    "    assert config.base_dir.exists(), \"Failed to create base directory\"\n",
    "    print(\"✅ Directory structure created\")\n",
    "    \n",
    "    # Test 2: Database connection\n",
    "    db_manager = DatabaseManager(config)\n",
    "    test_count = db_manager.conn.execute(\"SELECT COUNT(*) FROM images\").fetchone()[0]\n",
    "    print(f\"✅ Database connected (current images: {test_count})\")\n",
    "    \n",
    "    # Test 3: Image processing\n",
    "    processor = ImageProcessor(config)\n",
    "    print(\"✅ Image processor initialized\")\n",
    "    \n",
    "    # Test 4: CLIP model loading (if GPU available)\n",
    "    try:\n",
    "        embedding_gen = EmbeddingGenerator(config)\n",
    "        print(\"✅ CLIP model loaded\")\n",
    "    except:\n",
    "        print(\"⚠️ CLIP model failed to load (might need GPU)\")\n",
    "    \n",
    "    print(\"\\n✅ All components tested successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714f42f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Running component tests...\n",
      "🧪 Testing Pipeline Components...\n",
      "✅ Directory structure created\n",
      "✅ Database connected (current images: 0)\n",
      "✅ Image processor initialized\n",
      "🔧 Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CLIP model loaded\n",
      "\n",
      "✅ All components tested successfully!\n",
      "\n",
      "============================================================\n",
      "🚀 STARTING INTERIOR DESIGN DATA FOUNDATION PIPELINE\n",
      "============================================================\n",
      "🔧 Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 1909.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 RUNNING COMPLETE DATA FOUNDATION PIPELINE\n",
      "\n",
      "==================================================\n",
      "🚀 STARTING DATA COLLECTION PHASE\n",
      "==================================================\n",
      "\n",
      "📊 Collecting from HuggingFace: mehradaria/home-design\n",
      "❌ Failed to load dataset mehradaria/home-design: Dataset 'mehradaria/home-design' doesn't exist on the Hub or cannot be accessed.\n",
      "\n",
      "📊 Collecting from HuggingFace: Hovhannes/interior-design-dataset\n",
      "❌ Failed to load dataset Hovhannes/interior-design-dataset: Dataset 'Hovhannes/interior-design-dataset' doesn't exist on the Hub or cannot be accessed.\n",
      "\n",
      "📊 Collecting from HuggingFace: keremberke/interior-design-image-detection\n",
      "❌ Failed to load dataset keremberke/interior-design-image-detection: Dataset 'keremberke/interior-design-image-detection' doesn't exist on the Hub or cannot be accessed.\n",
      "\n",
      "🤖 Collecting from Roboflow: interior-design-xvdpu/1\n",
      "loading Roboflow workspace...\n",
      "❌ Failed to load Roboflow project interior-design-xvdpu/1: {\n",
      "    \"error\": {\n",
      "        \"message\": \"Unsupported get request. Workspace with ID \\\"interior-design-xvdpu\\\" does not exist or cannot be loaded due to missing permissions.\",\n",
      "        \"status\": 404,\n",
      "        \"type\": \"GraphMethodException\",\n",
      "        \"hint\": \"You can see your available workspaces by issuing a GET request to /workspaces\"\n",
      "    }\n",
      "}\n",
      "\n",
      "🤖 Collecting from Roboflow: furniture-detection-irblm/1\n",
      "loading Roboflow workspace...\n",
      "❌ Failed to load Roboflow project furniture-detection-irblm/1: {\n",
      "    \"error\": {\n",
      "        \"message\": \"Unsupported get request. Workspace with ID \\\"furniture-detection-irblm\\\" does not exist or cannot be loaded due to missing permissions.\",\n",
      "        \"status\": 404,\n",
      "        \"type\": \"GraphMethodException\",\n",
      "        \"hint\": \"You can see your available workspaces by issuing a GET request to /workspaces\"\n",
      "    }\n",
      "}\n",
      "\n",
      "📦 Collecting from Kaggle: jtylor84/visualizing-home-values\n",
      "⚠️ Kaggle credentials not found. Please set up ~/.kaggle/kaggle.json\n",
      "\n",
      "📦 Collecting from Kaggle: akshitmadan/interior-design-dataset\n",
      "⚠️ Kaggle credentials not found. Please set up ~/.kaggle/kaggle.json\n",
      "\n",
      "📊 Total images collected: 0\n",
      "❌ No images collected. Please check your API keys and dataset configurations.\n",
      "\n",
      "🎉 Pipeline execution complete!\n",
      "📂 Your data is ready in: interior_design_data\n",
      "\n",
      "Next steps:\n",
      "1. Review the collected data in the database\n",
      "2. Fine-tune the room/style classifiers with labeled data\n",
      "3. Start building the recommendation engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PART 9: MAIN EXECUTION\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup environment\n",
    "    setup_environment()\n",
    "    \n",
    "    # Create configuration\n",
    "    config = DataConfig()\n",
    "    \n",
    "    # Optional: Customize configuration\n",
    "    # config.huggingface_datasets = [\"your_custom_dataset\"]\n",
    "    # config.room_types = [\"living_room\", \"bedroom\"]  # Focus on these two\n",
    "    \n",
    "    # Run tests\n",
    "    print(\"🔍 Running component tests...\")\n",
    "    test_pipeline_components()\n",
    "    \n",
    "    # Create and run pipeline\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🚀 STARTING INTERIOR DESIGN DATA FOUNDATION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pipeline = DataPipeline(config)\n",
    "    \n",
    "    # You can run phases individually:\n",
    "    # metadata = pipeline.run_collection_phase(use_roboflow=False, max_samples_per_dataset=50)\n",
    "    # processed = pipeline.run_processing_phase(metadata)\n",
    "    # ...\n",
    "    \n",
    "    # Or run the complete pipeline:\n",
    "    pipeline.run_full_pipeline()\n",
    "    \n",
    "    print(\"\\n🎉 Pipeline execution complete!\")\n",
    "    print(f\"📂 Your data is ready in: {config.base_dir}\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Review the collected data in the database\")\n",
    "    print(\"2. Fine-tune the room/style classifiers with labeled data\")\n",
    "    print(\"3. Start building the recommendation engine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playbooktv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
